{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# pyright: reportUnusedExpression=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     from google.colab import auth  # pyright: ignore [reportMissingImports]\n",
    "\n",
    "#     auth.authenticate_user()\n",
    "#     %pip install --quiet keyring keyrings.google-artifactregistry-auth  # type: ignore # noqa\n",
    "#     %pip install --quiet genjax==0.7.0 genstudio==2024.9.7 --extra-index-url https://us-west1-python.pkg.dev/probcomp-caliban/probcomp/simple/  # type: ignore # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Exercises on the Localization Tutorial\n",
    "\n",
    "## Setup\n",
    "\n",
    "Here are two large notebook cells.  The first cell declares all the reusable components from the tutorial (modeling and inference gadgets, and plotting abstractions), making them globally available while performing no significant computation.  The second cell gathers the main visualization recipes in a series of commented blocks; each block can be run independently.\n",
    "\n",
    "After running the first of these cells, skip below to the following sections, which contain the exercises *per se*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Global includes\n",
    "\n",
    "import json\n",
    "import genstudio.plot as Plot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import genjax\n",
    "from genjax import ChoiceMapBuilder as C\n",
    "from genjax.typing import Array, FloatArray, PRNGKey, IntArray\n",
    "from penzai import pz\n",
    "from typing import TypeVar, Generic, Callable\n",
    "from genstudio.plot import js\n",
    "\n",
    "html = Plot.Hiccup\n",
    "\n",
    "\n",
    "# Map data\n",
    "\n",
    "def create_segments(points):\n",
    "    \"\"\"\n",
    "    Given an array of points of shape (N, 2), return an array of\n",
    "    pairs of points. [p_1, p_2, p_3, ...] -> [[p_1, p_2], [p_2, p_3], ...]\n",
    "    where each p_i is [x_i, y_i]\n",
    "    \"\"\"\n",
    "    return jnp.stack([points, jnp.roll(points, shift=-1, axis=0)], axis=1)\n",
    "\n",
    "\n",
    "def make_world(wall_verts, clutters_vec):\n",
    "    \"\"\"\n",
    "    Constructs the world by creating segments for walls and clutters, calculates the bounding box, and prepares the simulation parameters.\n",
    "\n",
    "    Args:\n",
    "    - wall_verts (list of list of float): A list of 2D points representing the vertices of walls.\n",
    "    - clutters_vec (list of list of list of float): A list where each element is a list of 2D points representing the vertices of a clutter.\n",
    "    - start (Pose): The starting pose of the robot.\n",
    "    - controls (list of Control): Control actions for the robot.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the world configuration, the initial state, and the total number of control steps.\n",
    "    \"\"\"\n",
    "    # Create segments for walls and clutters\n",
    "    walls = create_segments(wall_verts)\n",
    "    clutters = jax.vmap(create_segments)(clutters_vec)\n",
    "\n",
    "    # Combine all points for bounding box calculation\n",
    "    all_points = jnp.vstack(\n",
    "        (jnp.array(wall_verts), jnp.concatenate(clutters_vec))\n",
    "    )\n",
    "    x_min, y_min = jnp.min(all_points, axis=0)\n",
    "    x_max, y_max = jnp.max(all_points, axis=0)\n",
    "\n",
    "    # Calculate bounding box, box size, and center point\n",
    "    bounding_box = jnp.array([[x_min, x_max], [y_min, y_max], [-jnp.pi, +jnp.pi]])\n",
    "    box_size = max(x_max - x_min, y_max - y_min)\n",
    "    center_point = jnp.array([(x_min + x_max) / 2, (y_min + y_max) / 2])\n",
    "\n",
    "    return {\n",
    "            \"walls\": walls,\n",
    "            \"wall_verts\": wall_verts,\n",
    "            \"clutters\": clutters,\n",
    "            \"bounding_box\": bounding_box,\n",
    "            \"box_size\": box_size,\n",
    "            \"center_point\": center_point,\n",
    "        }\n",
    "\n",
    "def load_file(file_name):\n",
    "    # load from cwd or its parent\n",
    "    # (differs depending on dev environment)\n",
    "    try:\n",
    "        with open(file_name) as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        with open(f\"../{file_name}\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def load_world(file_name):\n",
    "    \"\"\"\n",
    "    Loads the world configuration from a specified file and constructs the world.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): The name of the file containing the world configuration.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the world configuration, the initial state, and the total number of control steps.\n",
    "    \"\"\"\n",
    "    # Try both the direct path and one directory up\n",
    "    data = load_file(file_name)\n",
    "\n",
    "    walls_vec = jnp.array(data[\"wall_verts\"])\n",
    "    clutters_vec = jnp.array(data[\"clutter_vert_groups\"])\n",
    "\n",
    "    return make_world(walls_vec, clutters_vec)\n",
    "\n",
    "world = load_world(\"world.json\")\n",
    "\n",
    "walls_plot = Plot.new(\n",
    "    Plot.line(\n",
    "        world[\"wall_verts\"],\n",
    "        strokeWidth=2,\n",
    "        stroke=\"#ccc\",\n",
    "    ),\n",
    "    {\"margin\": 0, \"inset\": 50, \"width\": 500, \"axis\": None, \"aspectRatio\": 1},\n",
    "    Plot.domain(world[\"bounding_box\"][0]),\n",
    ")\n",
    "\n",
    "world_plot = (\n",
    "    walls_plot\n",
    "    + Plot.frame(strokeWidth=4, stroke=\"#ddd\")\n",
    "    + Plot.color_legend()\n",
    ")\n",
    "\n",
    "clutters_plot = (\n",
    "    [Plot.line(c[:, 0], fill=Plot.constantly(\"clutters\")) for c in world[\"clutters\"]],\n",
    "    Plot.color_map({\"clutters\": \"magenta\"}),\n",
    ")\n",
    "\n",
    "\n",
    "# Poses\n",
    "\n",
    "@pz.pytree_dataclass\n",
    "class Pose(genjax.PythonicPytree):\n",
    "    p: FloatArray\n",
    "    hd: FloatArray\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Pose(p={self.p}, hd={self.hd})\"\n",
    "\n",
    "    def as_array(self):\n",
    "        return jnp.append(self.p, self.hd)\n",
    "\n",
    "    def as_dict(self):\n",
    "        return {\"p\": self.p, \"hd\": self.hd}\n",
    "\n",
    "    def dp(self):\n",
    "        return jnp.array([jnp.cos(self.hd), jnp.sin(self.hd)])\n",
    "\n",
    "    def step_along(self, s: float) -> \"Pose\":\n",
    "        \"\"\"\n",
    "        Moves along the direction of the pose by a scalar and returns a new Pose.\n",
    "\n",
    "        Args:\n",
    "            s (float): The scalar distance to move along the pose's direction.\n",
    "\n",
    "        Returns:\n",
    "            Pose: A new Pose object representing the moved position.\n",
    "        \"\"\"\n",
    "        new_p = self.p + s * self.dp()\n",
    "        return Pose(new_p, self.hd)\n",
    "\n",
    "    def apply_control(self, control):\n",
    "        return Pose(self.p + control.ds * self.dp(), self.hd + control.dhd)\n",
    "\n",
    "    def rotate(self, a: float) -> \"Pose\":\n",
    "        \"\"\"\n",
    "        Rotates the pose by angle 'a' (in radians) and returns a new Pose.\n",
    "\n",
    "        Args:\n",
    "            a (float): The angle in radians to rotate the pose.\n",
    "\n",
    "        Returns:\n",
    "            Pose: A new Pose object representing the rotated pose.\n",
    "        \"\"\"\n",
    "        return Pose(self.p, self.hd + a)\n",
    "\n",
    "def random_pose(k):\n",
    "    p_array = jax.random.uniform(k, shape=(3,),\n",
    "        minval=world[\"bounding_box\"][:, 0],\n",
    "        maxval=world[\"bounding_box\"][:, 1])\n",
    "    return Pose(p_array[0:2], p_array[2])\n",
    "\n",
    "def pose_wings(pose, opts={}):\n",
    "    return Plot.line(js(\"\"\"\n",
    "                   const pose = %1;\n",
    "                   let positions = pose.p;\n",
    "                   let angles = pose.hd;\n",
    "                   if (typeof angles === 'number') {{\n",
    "                       positions = [positions];\n",
    "                       angles = [angles];\n",
    "                   }}\n",
    "                   return Array.from(positions).flatMap((p, i) => {{\n",
    "                     const angle = angles[i]\n",
    "                     const wingAngle = Math.PI / 12\n",
    "                     const wingLength = 0.6\n",
    "                     const wing1 = [\n",
    "                       p[0] - wingLength * Math.cos(angle + wingAngle),\n",
    "                       p[1] - wingLength * Math.sin(angle + wingAngle),\n",
    "                       i\n",
    "                     ]\n",
    "                     const center = [p[0], p[1], i]\n",
    "                     const wing2 = [\n",
    "                       p[0] - wingLength * Math.cos(angle - wingAngle),\n",
    "                       p[1] - wingLength * Math.sin(angle - wingAngle),\n",
    "                       i\n",
    "                     ]\n",
    "                     return [wing1, center, wing2]\n",
    "                   }})\n",
    "                   \"\"\", pose, expression=False),\n",
    "                z=\"2\",\n",
    "                **opts)\n",
    "\n",
    "def pose_body(pose, opts={}):\n",
    "    return Plot.dot(js(\"typeof %1.hd === 'number' ? [%1.p] : %1.p\", pose), {\"r\": 4} | opts)\n",
    "\n",
    "def pose_plots(poses, wing_opts={}, body_opts={}, **opts):\n",
    "    \"\"\"\n",
    "    Creates a plot visualization for one or more poses.\n",
    "\n",
    "    Args:\n",
    "        poses_or_stateKey: Either a collection of poses or a state key string\n",
    "        **opts: Optional styling applied to both lines and dots. If 'color' is provided,\n",
    "               it will be used as 'stroke' for lines and 'fill' for dots.\n",
    "\n",
    "    Returns:\n",
    "        A plot object showing the poses with direction indicators\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle color -> stroke/fill conversion\n",
    "    if \"color\" in opts:\n",
    "        wing_opts = wing_opts | {\"stroke\": opts[\"color\"]}\n",
    "        body_opts = body_opts | {\"fill\": opts[\"color\"]}\n",
    "    return (\n",
    "        pose_wings(poses, opts | wing_opts) + pose_body(poses, opts | body_opts)\n",
    "    )\n",
    "\n",
    "def pose_widget(label, initial_pose, **opts):\n",
    "    return (\n",
    "        pose_plots(js(f\"$state.{label}\"),\n",
    "            render=Plot.renderChildEvents({\"onDrag\": js(\n",
    "                f\"\"\"\n",
    "                (e) => {{\n",
    "                    if (e.shiftKey) {{\n",
    "                        const dx = e.x - $state.{label}.p[0];\n",
    "                        const dy = e.y - $state.{label}.p[1];\n",
    "                        const angle = Math.atan2(dy, dx);\n",
    "                        $state.update({{{label}: {{hd: angle, p: $state.{label}.p}}}})\n",
    "                    }} else {{\n",
    "                        $state.update({{{label}: {{hd: $state.{label}.hd, p: [e.x, e.y]}}}})\n",
    "                    }}\n",
    "                }}\n",
    "                \"\"\")}), **opts)\n",
    "        | Plot.initialState({label: initial_pose.as_dict()}, sync=label)\n",
    "    )\n",
    "\n",
    "\n",
    "# Ideal sensors\n",
    "\n",
    "def distance(p, seg, PARALLEL_TOL=1.0e-6):\n",
    "    \"\"\"\n",
    "    Computes the distance from a pose to a segment, considering the pose's direction.\n",
    "\n",
    "    Args:\n",
    "    - p: The Pose object.\n",
    "    - seg: The segment [p1, p2].\n",
    "\n",
    "    Returns:\n",
    "    - float: The distance to the segment. Returns infinity if no valid intersection is found.\n",
    "    \"\"\"\n",
    "    pdp = p.dp()\n",
    "    segdp = seg[1] - seg[0]\n",
    "    # Compute unique s, t such that p.p + s * pdp == seg[0] + t * segdp\n",
    "    pq = p.p - seg[0]\n",
    "    det = pdp[0] * segdp[1] - pdp[1] * segdp[0]\n",
    "    st = jnp.where(\n",
    "        jnp.abs(det) < PARALLEL_TOL,\n",
    "        jnp.array([jnp.nan, jnp.nan]),\n",
    "        jnp.array([\n",
    "            segdp[0] * pq[1] - segdp[1] * pq[0],\n",
    "              pdp[0] * pq[1] -   pdp[1] * pq[0]\n",
    "        ]) / det\n",
    "    )\n",
    "    return jnp.where(\n",
    "        (st[0] >= 0) & (st[1] >= 0) & (st[1] <= 1),\n",
    "        st[0],\n",
    "        jnp.inf\n",
    "    )\n",
    "\n",
    "sensor_settings = {\n",
    "    \"fov\": 2 * jnp.pi * (2 / 3),\n",
    "    \"num_angles\": 41,\n",
    "    \"box_size\": world[\"box_size\"],\n",
    "}\n",
    "\n",
    "def sensor_distance(pose, walls, box_size):\n",
    "    d = jnp.min(jax.vmap(distance, in_axes=(None, 0))(pose, walls))\n",
    "    # Capping to a finite value avoids issues below.\n",
    "    return jnp.where(jnp.isinf(d), 2 * box_size, d)\n",
    "\n",
    "def make_sensor_angles(sensor_settings):\n",
    "    na = sensor_settings[\"num_angles\"]\n",
    "    return sensor_settings[\"fov\"] * (jnp.arange(na) - ((na - 1) / 2)) / (na - 1)\n",
    "\n",
    "sensor_angles = make_sensor_angles(sensor_settings)\n",
    "\n",
    "def ideal_sensor(pose):\n",
    "    return jax.vmap(\n",
    "        lambda angle: sensor_distance(pose.rotate(angle), world[\"walls\"], sensor_settings[\"box_size\"])\n",
    "    )(sensor_angles)\n",
    "\n",
    "def plot_sensors(pose, readings, sensor_angles, show_legend=False):\n",
    "    return Plot.Import(\"\"\"export const projections = (pose, readings, angles) => Array.from({length: readings.length}, (_, i) => {\n",
    "                const angle = angles[i] + pose.hd\n",
    "                const reading = readings[i]\n",
    "                return [pose.p[0] + reading * Math.cos(angle), pose.p[1] + reading * Math.sin(angle)]\n",
    "            })\"\"\",\n",
    "            refer=[\"projections\"]) | (\n",
    "        Plot.line(\n",
    "            js(\"projections(%1, %2, %3).flatMap((projection, i) => [%1.p, projection, i])\", pose, readings, sensor_angles),\n",
    "            opacity=0.1,\n",
    "        ) +\n",
    "        Plot.dot(\n",
    "            js(\"projections(%1, %2, %3)\", pose, readings, sensor_angles),\n",
    "            r=2.75,\n",
    "            fill=\"#f80\"\n",
    "        ) +\n",
    "        Plot.cond(show_legend, Plot.colorMap({\"sensor rays\": \"rgb(0,0,0,0.1)\", \"sensor readings\": \"#f80\"}) | Plot.colorLegend())\n",
    "    )\n",
    "\n",
    "def pose_at(state, label):\n",
    "    pose_dict = getattr(state, label)\n",
    "    return Pose(jnp.array(pose_dict[\"p\"]), jnp.array(pose_dict[\"hd\"]))\n",
    "\n",
    "def update_ideal_sensors(widget, label):\n",
    "    widget.state.update({\n",
    "        (label + \"_readings\"): ideal_sensor(pose_at(widget.state, label))\n",
    "    })\n",
    "\n",
    "\n",
    "# Noisy sensors\n",
    "\n",
    "model_sensor_noise = 0.1\n",
    "\n",
    "@genjax.gen\n",
    "def sensor_model_one(pose, angle, sensor_noise):\n",
    "    return (\n",
    "        genjax.normal(\n",
    "            sensor_distance(pose.rotate(angle), world[\"walls\"], sensor_settings[\"box_size\"]),\n",
    "            sensor_noise,\n",
    "        )\n",
    "        @ \"distance\"\n",
    "    )\n",
    "\n",
    "sensor_model = sensor_model_one.vmap(in_axes=(None, 0, None))\n",
    "\n",
    "def noisy_sensor(key, pose, sensor_noise):\n",
    "    return sensor_model.propose(key, (pose, sensor_angles, sensor_noise))[2]\n",
    "\n",
    "def noise_slider(key, label, init):\n",
    "    return Plot.Slider(\n",
    "        key=key,\n",
    "        label=label,\n",
    "        showValue=True,\n",
    "        range=[0.01, 5.0],\n",
    "        step=0.01,\n",
    "    ) | Plot.initialState({key: init}, sync={key})\n",
    "\n",
    "def update_noisy_sensors(widget, pose_key, slider_key):\n",
    "    k1, k2 = jax.random.split(jax.random.wrap_key_data(widget.state.k))\n",
    "    readings = noisy_sensor(k1, pose_at(widget.state, pose_key), float(getattr(widget.state, slider_key)))\n",
    "    widget.state.update({\n",
    "        \"k\": jax.random.key_data(k2),\n",
    "        (pose_key + \"_readings\"): readings\n",
    "    })\n",
    "    return readings\n",
    "\n",
    "\n",
    "# Pose priors\n",
    "\n",
    "# Uniform prior over the whole map.\n",
    "# (This is just a recapitulation of `random_pose` from above.)\n",
    "\n",
    "@genjax.gen\n",
    "def uniform_pose(mins, maxes):\n",
    "    p_array = genjax.uniform(mins, maxes) @ \"p_array\"\n",
    "    return Pose(p_array[0:2], p_array[2])\n",
    "\n",
    "whole_map_prior = uniform_pose.partial_apply(\n",
    "    world[\"bounding_box\"][:, 0],\n",
    "    world[\"bounding_box\"][:, 1]\n",
    ")\n",
    "\n",
    "def whole_map_cm_builder(pose):\n",
    "    return C[\"p_array\"].set(pose.as_array())\n",
    "\n",
    "# Even mixture of uniform priors over two rooms.\n",
    "\n",
    "room_mixture = jnp.ones(2) / 2\n",
    "room1 = jnp.array([[12.83, 15.81], [11.19, 15.26], [-jnp.pi, +jnp.pi]])\n",
    "room2 = jnp.array([[15.73, 18.90], [ 5.79,  9.57], [-jnp.pi, +jnp.pi]])\n",
    "\n",
    "two_room_prior = genjax.mix(\n",
    "    uniform_pose.partial_apply(room1[:, 0], room1[:, 1]),\n",
    "    uniform_pose.partial_apply(room2[:, 0], room2[:, 1])\n",
    ").partial_apply(jnp.log(room_mixture), (), ())\n",
    "\n",
    "def two_room_cm_builder(pose):\n",
    "    return (\n",
    "        C[\"mixture_component\"].set(jnp.array(pose.p[1] < 10, int))\n",
    "        | C[\"component_sample\", \"p_array\"].set(pose.as_array())\n",
    "    )\n",
    "\n",
    "# Prior localized around a single pose\n",
    "\n",
    "pose_for_localized_prior = Pose(jnp.array([2.0, 16.0]), jnp.array(0.0))\n",
    "spread_of_localized_prior = (0.1, 0.75)\n",
    "@genjax.gen\n",
    "def localized_prior():\n",
    "    p = (\n",
    "        genjax.mv_normal_diag(\n",
    "            pose_for_localized_prior.p,\n",
    "            spread_of_localized_prior[0] * jnp.ones(2)\n",
    "        )\n",
    "        @ \"p\"\n",
    "    )\n",
    "    hd = (\n",
    "        genjax.normal(\n",
    "            pose_for_localized_prior.hd,\n",
    "            spread_of_localized_prior[1]\n",
    "        )\n",
    "        @ \"hd\"\n",
    "    )\n",
    "    return Pose(p, hd)\n",
    "\n",
    "def localized_cm_builder(pose):\n",
    "    return C[\"p\"].set(pose.p) | C[\"hd\"].set(pose.hd)\n",
    "\n",
    "\n",
    "# Joint model\n",
    "\n",
    "model_dispatch = {\n",
    "    \"whole_map\": (whole_map_prior, whole_map_cm_builder),\n",
    "    \"two_room\": (two_room_prior, two_room_cm_builder),\n",
    "    \"localized\": (localized_prior, localized_cm_builder),\n",
    "}\n",
    "\n",
    "def make_posterior_density_fn(prior_label, readings, model_noise):\n",
    "    prior, cm_builder = model_dispatch[prior_label]\n",
    "    @genjax.gen\n",
    "    def joint_model():\n",
    "        pose = prior() @ \"pose\"\n",
    "        sensor = sensor_model(pose, sensor_angles, model_noise) @ \"sensor\"  # noqa: F841\n",
    "    return jax.jit(\n",
    "        lambda pose:\n",
    "            joint_model.assess(\n",
    "                C[\"pose\"].set(cm_builder(pose)) | C[\"sensor\", \"distance\"].set(readings),\n",
    "                ()\n",
    "            )[0]\n",
    "    )\n",
    "\n",
    "\n",
    "# \"Camera widget\" code\n",
    "\n",
    "def on_camera_button(button_handler):\n",
    "    def handler(widget, _):\n",
    "        k1, k2 = jax.random.split(jax.random.wrap_key_data(widget.state.k))\n",
    "        widget.state.update({\n",
    "            \"k\": jax.random.key_data(k1),\n",
    "            \"target\": widget.state.camera,\n",
    "        })\n",
    "        readings = update_noisy_sensors(widget, \"target\", \"world_noise\")\n",
    "        button_handler(widget, k2, readings)\n",
    "        widget.state.update({\n",
    "            \"target_exists\": True,\n",
    "        })\n",
    "    return handler\n",
    "\n",
    "def camera_widget(\n",
    "        k, camera_pose,\n",
    "        button_label, button_handler,\n",
    "        result_plots=Plot.dot([jnp.sum(world[\"bounding_box\"], axis=1)[0:2]], opacity=1),\n",
    "        bottom_elements=(),\n",
    "        initial_state={},\n",
    "        sync=set()):\n",
    "    return (\n",
    "        (\n",
    "            world_plot\n",
    "            + Plot.cond(js(\"$state.target_exists\"),\n",
    "                result_plots\n",
    "                + plot_sensors(js(\"$state.target\"), js(\"$state.target_readings\"), sensor_angles)\n",
    "                + pose_plots(js(\"$state.target\"), color=\"red\")\n",
    "            )\n",
    "            + pose_widget(\"camera\", camera_pose, color=\"blue\")\n",
    "        )\n",
    "        | noise_slider(\"world_noise\", \"World/data noise = \", model_sensor_noise)\n",
    "        | Plot.html([\n",
    "            \"p\",\n",
    "            \"Prior:\",\n",
    "            [\n",
    "                \"select\",\n",
    "                {\"onChange\": js(\"(e) => $state.prior = e.target.value\")},\n",
    "                [\"option\", {\"value\": \"whole_map\", \"selected\": \"True\"}, \"whole map\"],\n",
    "                [\"option\", {\"value\": \"two_room\"}, \"two room\"],\n",
    "                [\"option\", {\"value\": \"localized\"}, \"localized\"],\n",
    "            ]\n",
    "        ])\n",
    "        | noise_slider(\"model_noise\", \"Model/inference noise = \", model_sensor_noise)\n",
    "        | (\n",
    "            Plot.html([\n",
    "                \"button\",\n",
    "                {\n",
    "                    \"class\": \"w-24 px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 active:bg-blue-700\",\n",
    "                    \"onClick\": on_camera_button(button_handler)\n",
    "                },\n",
    "                button_label\n",
    "            ])\n",
    "            & Plot.html(\n",
    "                Plot.js(\"\"\"`camera = Pose([${$state.camera.p.map((x) => x.toFixed(2))}], ${$state.camera.hd.toFixed(2)})`\"\"\")\n",
    "            )\n",
    "            & Plot.html(\n",
    "                Plot.js(\"\"\"$state.target_exists ?\n",
    "                                `target = Pose([${$state.target.p.map((x) => x.toFixed(2))}], ${$state.target.hd.toFixed(2)})` : ''\"\"\")\n",
    "            )\n",
    "            & bottom_elements\n",
    "        )\n",
    "        | Plot.initialState(\n",
    "            {\n",
    "                \"k\": jax.random.key_data(k),\n",
    "                \"target_exists\": False,\n",
    "                \"target\": {\"p\": None, \"hd\": None},\n",
    "                \"target_readings\": [],\n",
    "                \"prior\": \"whole_map\"\n",
    "            } | initial_state,\n",
    "            sync=({\"k\", \"target\", \"camera_readings\", \"prior\"} | sync))\n",
    "    )\n",
    "\n",
    "\n",
    "# Grid utils\n",
    "\n",
    "def make_grid(bounds, ns):\n",
    "    return [dim.reshape(-1) for dim in jnp.meshgrid(*(jnp.linspace(*bound, num=n) for (bound, n) in zip(bounds, ns)))]\n",
    "\n",
    "def make_poses_grid_array(bounds, ns):\n",
    "    grid_xs, grid_ys, grid_hds = make_grid(bounds, ns)\n",
    "    return jnp.array([grid_xs, grid_ys]).T, grid_hds\n",
    "\n",
    "def make_poses_grid(bounds, ns):\n",
    "    return Pose(*make_poses_grid_array(bounds, ns))\n",
    "\n",
    "\n",
    "# Robot programs\n",
    "\n",
    "@pz.pytree_dataclass\n",
    "class Control(genjax.PythonicPytree):\n",
    "    ds: FloatArray\n",
    "    dhd: FloatArray\n",
    "\n",
    "def load_robot_program(file_name):\n",
    "    \"\"\"\n",
    "    Loads the robot program from a specified file.\n",
    "\n",
    "    Args:\n",
    "    - file_name (str): The name of the file containing the world configuration.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the initial state, and the total number of control steps.\n",
    "    \"\"\"\n",
    "    robot_program = load_file(file_name)\n",
    "\n",
    "    start = Pose(\n",
    "        jnp.array(robot_program[\"start_pose\"][\"p\"], dtype=float),\n",
    "        jnp.array(robot_program[\"start_pose\"][\"hd\"], dtype=float),\n",
    "    )\n",
    "\n",
    "    cs = jnp.array([[c[\"ds\"], c[\"dhd\"]] for c in robot_program[\"program_controls\"]])\n",
    "    controls = Control(cs[:, 0], cs[:, 1])\n",
    "\n",
    "    # We prepend a zero-effect control step to the control array. This allows\n",
    "    # numerous simplifications in what follows: we can consider the initial\n",
    "    # pose uncertainty as well as each subsequent step to be the same function\n",
    "    # of current position and control step.\n",
    "    noop_control = Control(jnp.array(0.0), jnp.array(0.0))\n",
    "    controls = controls.prepend(noop_control)\n",
    "\n",
    "    # Determine the total number of control steps\n",
    "    T = len(controls.ds)\n",
    "\n",
    "    return ({\"start\": start, \"controls\": controls}, T)\n",
    "\n",
    "world[\"bounce\"] = 0.1\n",
    "robot_inputs, T = load_robot_program(\"robot_program.json\")\n",
    "\n",
    "\n",
    "# Integrating controls / applying robot programs\n",
    "\n",
    "def diag(x): return (x, x)\n",
    "\n",
    "def integrate_controls_unphysical(robot_inputs):\n",
    "    \"\"\"\n",
    "    Integrates the controls to generate a path from the starting pose.\n",
    "\n",
    "    This function takes the initial pose and a series of control steps (ds for distance, dhd for heading change)\n",
    "    and computes the resulting path by applying each control step sequentially.\n",
    "\n",
    "    Args:\n",
    "    - robot_inputs (dict): A dictionary containing the starting pose and control steps.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of Pose instances representing the path taken by applying the controls.\n",
    "    \"\"\"\n",
    "    return jax.lax.scan(\n",
    "        lambda pose, control: diag(pose.apply_control(control)),\n",
    "        robot_inputs[\"start\"],\n",
    "        robot_inputs[\"controls\"],\n",
    "    )[1]\n",
    "\n",
    "@jax.jit\n",
    "def physical_step(p1: FloatArray, p2: FloatArray, hd):\n",
    "    \"\"\"\n",
    "    Computes a physical step considering wall collisions and bounces.\n",
    "\n",
    "    Args:\n",
    "    - p1, p2: Start and end points of the step.\n",
    "    - hd: Heading direction.\n",
    "\n",
    "    Returns:\n",
    "    - Pose: The new pose after taking the step, considering potential wall collisions.\n",
    "    \"\"\"\n",
    "    # Calculate step direction and length\n",
    "    step_direction = p2 - p1\n",
    "    step_length = jnp.linalg.norm(step_direction)\n",
    "    step_pose = Pose(p1, jnp.arctan2(step_direction[1], step_direction[0]))\n",
    "\n",
    "    # Calculate distances to all walls\n",
    "    distances = jax.vmap(distance, in_axes=(None, 0))(step_pose, world[\"walls\"])\n",
    "\n",
    "    # Find the closest wall\n",
    "    closest_wall_index = jnp.argmin(distances)\n",
    "    closest_wall_distance = distances[closest_wall_index]\n",
    "    closest_wall = world[\"walls\"][closest_wall_index]\n",
    "\n",
    "    # Calculate wall normal and collision point\n",
    "    collision_point = p1 + closest_wall_distance * step_pose.dp()\n",
    "    wall_direction = closest_wall[1] - closest_wall[0]\n",
    "    normalized_wall_direction = wall_direction / jnp.linalg.norm(wall_direction)\n",
    "    wall_normal = jnp.array([-normalized_wall_direction[1], normalized_wall_direction[0]])\n",
    "\n",
    "    # Ensure wall_normal points away from the robot's direction\n",
    "    wall_normal = jnp.where(\n",
    "        jnp.dot(step_pose.dp(), wall_normal) > 0, -wall_normal, wall_normal\n",
    "    )\n",
    "\n",
    "    # Calculate bounce off point\n",
    "    bounce_off_point: FloatArray = collision_point + world[\"bounce\"] * wall_normal\n",
    "\n",
    "    # Determine final position based on whether a collision occurred\n",
    "    final_position = jnp.where(\n",
    "        closest_wall_distance > step_length, p2, bounce_off_point\n",
    "    )\n",
    "\n",
    "    return Pose(final_position, hd)\n",
    "\n",
    "def integrate_controls_physical(robot_inputs):\n",
    "    \"\"\"\n",
    "    Integrates controls to generate a path, taking into account physical interactions with walls.\n",
    "\n",
    "    Args:\n",
    "    - robot_inputs: Dictionary containing the starting pose and control steps.\n",
    "\n",
    "    Returns:\n",
    "    - Pose: A Pose object representing the path taken by applying the controls.\n",
    "    \"\"\"\n",
    "    return jax.lax.scan(\n",
    "        lambda pose, control: diag(physical_step(\n",
    "                pose.p, pose.p + control.ds * pose.dp(), pose.hd + control.dhd\n",
    "            )),\n",
    "        robot_inputs[\"start\"],\n",
    "        robot_inputs[\"controls\"],\n",
    "    )[1]\n",
    "\n",
    "path_integrated = integrate_controls_physical(robot_inputs)\n",
    "\n",
    "\n",
    "# Step and path models\n",
    "\n",
    "@genjax.gen\n",
    "def step_model(motion_settings, start, control):\n",
    "    p = (\n",
    "        genjax.mv_normal_diag(\n",
    "            start.p + control.ds * start.dp(), motion_settings[\"p_noise\"] * jnp.ones(2)\n",
    "        )\n",
    "        @ \"p\"\n",
    "    )\n",
    "    hd = genjax.normal(start.hd + control.dhd, motion_settings[\"hd_noise\"]) @ \"hd\"\n",
    "    return physical_step(start.p, p, hd)\n",
    "\n",
    "degrees = jnp.pi / 180\n",
    "model_motion_settings = {\n",
    "    \"p_noise\": 0.15,\n",
    "    \"hd_noise\": 1 * degrees\n",
    "}\n",
    "\n",
    "@genjax.gen\n",
    "def path_model(motion_settings):\n",
    "    return (\n",
    "        step_model\n",
    "        .partial_apply(motion_settings)\n",
    "        .map(diag)\n",
    "        .scan()(robot_inputs[\"start\"], robot_inputs[\"controls\"])\n",
    "        @ \"steps\"\n",
    "    )\n",
    "\n",
    "def confidence_circle(p, p_noise):\n",
    "    return Plot.ellipse(\n",
    "        p,\n",
    "        r=2.5 * p_noise,\n",
    "        fill=Plot.constantly(\"95% confidence region\"),\n",
    "    ) + Plot.color_map({\"95% confidence region\": \"rgba(255,0,0,0.25)\"})\n",
    "\n",
    "def plot_path_with_confidence(path, step):\n",
    "    prev_step = robot_inputs[\"start\"] if step == 0 else path[step - 1]\n",
    "    return (\n",
    "        world_plot\n",
    "        + confidence_circle(\n",
    "            [prev_step.apply_control(robot_inputs[\"controls\"][step]).p],\n",
    "            model_motion_settings[\"p_noise\"]\n",
    "        )\n",
    "        + [pose_plots(path[i]) for i in range(step)]\n",
    "        + pose_plots(path[step], color=Plot.constantly(\"next pose\"))\n",
    "        + Plot.color_map({\"previous poses\": \"black\", \"next pose\": \"green\"})\n",
    "    )\n",
    "\n",
    "def animate_path_and_sensors(path, readings, frame_key=None):\n",
    "    return Plot.Frames([\n",
    "        plot_path_with_confidence(path, step)\n",
    "        + plot_sensors(pose, readings[step], sensor_angles)\n",
    "        for step, pose in enumerate(path)\n",
    "    ], fps=2, key=frame_key)\n",
    "\n",
    "\n",
    "# Full model\n",
    "\n",
    "@genjax.gen\n",
    "def full_model_kernel(motion_settings, sensor_noise, state, control):\n",
    "    pose = step_model(motion_settings, state, control) @ \"pose\"\n",
    "    sensor_model(pose, sensor_angles, sensor_noise) @ \"sensor\"\n",
    "    return pose\n",
    "\n",
    "@genjax.gen\n",
    "def full_model(motion_settings, sensor_noise):\n",
    "    return (\n",
    "        full_model_kernel\n",
    "        .partial_apply(motion_settings, sensor_noise)\n",
    "        .map(diag)\n",
    "        .scan()(robot_inputs[\"start\"], robot_inputs[\"controls\"])\n",
    "        @ \"steps\"\n",
    "    )\n",
    "\n",
    "\n",
    "# THE DATA\n",
    "\n",
    "motion_settings_low_deviation = {\n",
    "    \"p_noise\": 0.05,\n",
    "    \"hd_noise\": (1 / 10) * degrees,\n",
    "}\n",
    "motion_settings_high_deviation = {\n",
    "    \"p_noise\": 0.5,\n",
    "    \"hd_noise\": 3 * degrees,\n",
    "}\n",
    "\n",
    "key = jax.random.key(0)\n",
    "key, k_low, k_high = jax.random.split(key, 3)\n",
    "trace_low_deviation = full_model.simulate(k_low, (motion_settings_low_deviation, model_sensor_noise))\n",
    "trace_high_deviation = full_model.simulate(k_high, (motion_settings_high_deviation, model_sensor_noise))\n",
    "\n",
    "def get_path(trace):\n",
    "    return trace.get_retval()[1]\n",
    "\n",
    "def get_sensors(trace):\n",
    "    return trace.get_choices()[\"steps\", \"sensor\", \"distance\"]\n",
    "\n",
    "def animate_full_trace(trace, frame_key=None):\n",
    "    path = get_path(trace)\n",
    "    readings = get_sensors(trace)\n",
    "    return animate_path_and_sensors(\n",
    "        path, readings, frame_key=frame_key\n",
    "    )\n",
    "\n",
    "def constraint_from_path(path):\n",
    "    c_ps = jax.vmap(lambda ix, p: C[\"steps\", ix, \"pose\", \"p\"].set(p))(\n",
    "        jnp.arange(T), path.p\n",
    "    )\n",
    "    c_hds = jax.vmap(lambda ix, hd: C[\"steps\", ix, \"pose\", \"hd\"].set(hd))(\n",
    "        jnp.arange(T), path.hd\n",
    "    )\n",
    "    return c_ps | c_hds\n",
    "\n",
    "\n",
    "path_low_deviation = get_path(trace_low_deviation)\n",
    "path_high_deviation = get_path(trace_high_deviation)\n",
    "observations_low_deviation = get_sensors(trace_low_deviation)\n",
    "observations_high_deviation = get_sensors(trace_high_deviation)\n",
    "constraints_low_deviation = C[\"steps\", \"sensor\", \"distance\"].set(observations_low_deviation)\n",
    "constraints_high_deviation = C[\"steps\", \"sensor\", \"distance\"].set(observations_high_deviation)\n",
    "\n",
    "constraints_path_integrated = constraint_from_path(path_integrated)\n",
    "\n",
    "\n",
    "# Whole-path importance resampling\n",
    "\n",
    "def importance_resample_unjitted(\n",
    "    key: PRNGKey, constraints: genjax.ChoiceMap, motion_settings, sensor_noise, N: int, K: int\n",
    "):\n",
    "    \"\"\"Produce K importance samples of depth N from the model. That is, K times, we\n",
    "    generate N importance samples conditioned by the constraints, and categorically\n",
    "    select one of them.\"\"\"\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    samples, log_weights = jax.vmap(full_model.importance, in_axes=(0, None, None))(\n",
    "        jax.random.split(key1, N * K), constraints, (motion_settings, sensor_noise)\n",
    "    )\n",
    "    winners = jax.vmap(genjax.categorical.propose)(\n",
    "        jax.random.split(key2, K), (jnp.reshape(log_weights, (K, N)),)\n",
    "    )[2]\n",
    "    # indices returned are relative to the start of the K-segment from which they were drawn.\n",
    "    # globalize the indices by adding back the index of the start of each segment.\n",
    "    winners += jnp.arange(0, N * K, N)\n",
    "    selected = jax.tree.map(lambda x: x[winners], samples)\n",
    "    return selected\n",
    "\n",
    "importance_resample = jax.jit(importance_resample_unjitted, static_argnums=(4, 5))\n",
    "\n",
    "\n",
    "def pytree_transpose(list_of_pytrees):\n",
    "  \"\"\"\n",
    "  Converts a list of pytrees of identical structure into a single pytree of lists.\n",
    "  \"\"\"\n",
    "  return jax.tree.map(lambda *xs: jnp.array(list(xs)), *list_of_pytrees)\n",
    "\n",
    "def plot_inference_result(title, samples_label, posterior_paths, target_path, history_paths=None):\n",
    "    return (\n",
    "        html(*title)\n",
    "        | (\n",
    "            world_plot\n",
    "            + (\n",
    "                [\n",
    "                    Plot.line(\n",
    "                        {\"x\": path.p[:, 0], \"y\": path.p[:, 1]},\n",
    "                        curve=\"linear\",\n",
    "                        opacity=0.05,\n",
    "                        strokeWidth=2,\n",
    "                        stroke=\"red\"\n",
    "                    )\n",
    "                    for path in history_paths\n",
    "                ] if history_paths else []\n",
    "            )\n",
    "            + [\n",
    "                Plot.line(\n",
    "                    {\"x\": path.p[:, 0], \"y\": path.p[:, 1]},\n",
    "                    curve=\"linear\",\n",
    "                    opacity=0.2,\n",
    "                    strokeWidth=2,\n",
    "                    stroke=\"green\"\n",
    "                )\n",
    "                for path in posterior_paths\n",
    "            ]\n",
    "            + pose_plots(\n",
    "                target_path, fill=Plot.constantly(\"path to be inferred\"), opacity = 0.5, strokeWidth=2\n",
    "            )\n",
    "            + Plot.color_map({\n",
    "                samples_label: \"green\",\n",
    "                \"path to be inferred\": \"black\",\n",
    "            } | (\n",
    "               {\"culled paths\": \"red\"} if history_paths else {}\n",
    "            ))\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Sequential importance resampling\n",
    "\n",
    "StateT = TypeVar(\"StateT\")\n",
    "ControlT = TypeVar(\"ControlT\")\n",
    "\n",
    "class SISwithRejuvenation(Generic[StateT, ControlT]):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "     - a functional wrapper for the importance method of a generative function\n",
    "     - an initial state of type StateT, which should be a PyTree $z_0$\n",
    "     - a vector of control inputs, also a PyTree $u_i, of shape $(T, \\\\ldots)$\n",
    "     - an array of observations $y_i$, also of shape $(T, \\\\ldots)$\n",
    "    perform the inference technique known as Sequential Importance Sampling.\n",
    "\n",
    "    The signature of the GFI importance method is\n",
    "        key -> constraint -> args -> (trace, weight)\n",
    "    For importance sampling, this is vmapped over key to get\n",
    "        [keys] -> constraint -> args -> ([trace], [weight])\n",
    "    The functional wrapper's purpose is to maneuver the state and control\n",
    "    inputs into whatever argument shape the underlying model is expecting,\n",
    "    and to turn the observation at step $t$ into a choicemap asserting\n",
    "    that constraint.\n",
    "\n",
    "    You may also supply an SMCP3 rejuvenation function, whose signature is\n",
    "        key -> Trace[StateT] ->\n",
    "\n",
    "    After the object is constructed, SIS can be performed at any importance\n",
    "    depth with the `run` method, which will perform the following steps:\n",
    "\n",
    "     - inflate the initial value to a vector of size N of identical initial\n",
    "       values\n",
    "     - vmap over N keys generated from the supplied key\n",
    "     - each vmap cell will scan over the control inputs and observations\n",
    "\n",
    "    Between each step, categorical sampling with replacement is formed to\n",
    "    create a particle filter. Favorable importance draws are likely to\n",
    "    be replicated, and unfavorable ones discarded. The resampled vector of\n",
    "    states is sent the the next step, while the values drawn from the\n",
    "    importance sample and the indices chosen are emitted from the scan step,\n",
    "    where, at the end of the process, they will be available as matrices\n",
    "    of shape (N, T).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        init: StateT,\n",
    "        controls: ControlT,\n",
    "        observations: Array,\n",
    "        importance: Callable[\n",
    "            [PRNGKey, StateT, ControlT, Array], tuple[genjax.Trace[StateT], float]\n",
    "        ],\n",
    "        rejuvenate: Callable[\n",
    "            [PRNGKey, genjax.Trace[StateT], Array, StateT, ControlT], tuple[genjax.Trace[StateT], float]\n",
    "        ] | None = None,\n",
    "    ):\n",
    "        self.importance = jax.jit(importance)\n",
    "        self.rejuvenate = jax.jit(rejuvenate) if rejuvenate else None\n",
    "        self.init = init\n",
    "        self.controls = controls\n",
    "        self.observations = observations\n",
    "\n",
    "    class Result(Generic[StateT]):\n",
    "        \"\"\"This object contains all of the information generated by the SIS scan,\n",
    "        and offers some convenient methods to reconstruct the paths explored\n",
    "        (`flood_fill`) or ultimately chosen (`backtrack`).\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(\n",
    "            self, end: StateT, samples: genjax.Trace[StateT], indices: IntArray, rejuvenated: genjax.Trace[StateT]\n",
    "        ):\n",
    "            self.end = end\n",
    "            self.samples = samples.get_retval()\n",
    "            self.indices = indices\n",
    "            self.rejuvenated = rejuvenated.get_retval()\n",
    "            self.N = len(end)\n",
    "            self.T = len(self.rejuvenated)\n",
    "\n",
    "        def flood_fill(self) -> list[list[StateT]]:\n",
    "            complete_paths = []\n",
    "            active_paths = self.N * [[]]\n",
    "            for i in range(self.T):\n",
    "                new_active_paths = self.N * [None]\n",
    "                for (j, count) in enumerate(jnp.bincount(self.indices[i], length=self.N)):\n",
    "                    if count == 0:\n",
    "                        complete_paths.append(active_paths[j] + [self.samples[i][j]])\n",
    "                    new_active_paths[j] = active_paths[self.indices[i][j]] + [self.rejuvenated[i][j]]\n",
    "                active_paths = new_active_paths\n",
    "            return complete_paths + active_paths\n",
    "\n",
    "        def backtrack(self) -> list[list[StateT]]:\n",
    "            paths = [[p] for p in self.end]\n",
    "            for i in reversed(range(self.T - 1)):\n",
    "                for j in range(self.N):\n",
    "                    paths[j].insert(0, self.rejuvenated[i][self.indices[i + 1][j]])\n",
    "            return paths\n",
    "\n",
    "    def run(self, key: PRNGKey, N: int) -> dict:\n",
    "        def step(state, update):\n",
    "            particles, log_weights = state\n",
    "            key, control, observation = update\n",
    "            ks = jax.random.split(key, (3, N))\n",
    "            samples, log_weight_increments = jax.vmap(self.importance, in_axes=(0, 0, None, None))(\n",
    "                ks[0], particles, control, observation\n",
    "            )\n",
    "            indices = jax.vmap(genjax.categorical.propose, in_axes=(0, None))(\n",
    "                ks[1], (log_weights + log_weight_increments,)\n",
    "            )[2]\n",
    "            (resamples, antecedents) = jax.tree.map(lambda v: v[indices], (samples, particles))\n",
    "            if self.rejuvenate:\n",
    "                rejuvenated, new_log_weights = jax.vmap(self.rejuvenate, in_axes=(0, 0, 0, None, None))(\n",
    "                    ks[2],\n",
    "                    resamples,\n",
    "                    antecedents,\n",
    "                    control,\n",
    "                    observation\n",
    "                )\n",
    "            else:\n",
    "                rejuvenated, new_log_weights = resamples, jnp.zeros(log_weights.shape)\n",
    "            return (rejuvenated.get_retval(), new_log_weights), (samples, indices, rejuvenated)\n",
    "\n",
    "        init_array = jax.tree.map(\n",
    "            lambda a: jnp.broadcast_to(a, (N,) + a.shape), self.init\n",
    "        )\n",
    "        (end, _), (samples, indices, rejuvenated) = jax.lax.scan(\n",
    "            step,\n",
    "            (init_array, jnp.zeros(N)),\n",
    "            (\n",
    "                jax.random.split(key, len(self.controls)),\n",
    "                self.controls,\n",
    "                self.observations,\n",
    "            ),\n",
    "        )\n",
    "        return SISwithRejuvenation.Result(end, samples, indices, rejuvenated)\n",
    "\n",
    "def localization_sis(motion_settings, sensor_noise, observations):\n",
    "    return SISwithRejuvenation(\n",
    "        robot_inputs[\"start\"],\n",
    "        robot_inputs[\"controls\"],\n",
    "        observations,\n",
    "        lambda key, pose, control, observation: full_model_kernel.importance(\n",
    "            key,\n",
    "            C[\"sensor\", \"distance\"].set(observation),\n",
    "            (motion_settings, sensor_noise, pose, control),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "# SMCP3\n",
    "\n",
    "def run_SMCP3_step(fwd_proposal, bwd_proposal, key, sample, proposal_args):\n",
    "    k1, k2 = jax.random.split(key, 2)\n",
    "    _, fwd_proposal_weight, (fwd_update, bwd_choices) = fwd_proposal.propose(k1, (sample, proposal_args))\n",
    "    new_sample, model_weight_diff, _, _ = sample.update(k2, fwd_update)\n",
    "    bwd_proposal_weight, _ = bwd_proposal.assess(bwd_choices, (new_sample, proposal_args))\n",
    "    new_log_weight = model_weight_diff + bwd_proposal_weight - fwd_proposal_weight\n",
    "    return new_sample, new_log_weight\n",
    "\n",
    "# Forward proposal searches a nearby grid around the sample,\n",
    "# and returns an importance-resampled member.\n",
    "# The joint density (= the density from the full model) serves as\n",
    "# the unnormalized posterior density over steps.\n",
    "@genjax.gen\n",
    "def grid_fwd_proposal(sample, args):\n",
    "    base_grid, observation, full_model_args = args\n",
    "    observation_cm = C[\"sensor\", \"distance\"].set(observation)\n",
    "\n",
    "    log_weights = jax.vmap(\n",
    "        lambda p, hd:\n",
    "            full_model_kernel.assess(\n",
    "                observation_cm\n",
    "                | C[\"pose\", \"p\"].set(p + sample.get_retval().p)\n",
    "                | C[\"pose\", \"hd\"].set(hd + sample.get_retval().hd),\n",
    "                full_model_args\n",
    "            )[0]\n",
    "    )(*base_grid)\n",
    "    fwd_index = genjax.categorical(log_weights) @ \"fwd_index\"\n",
    "\n",
    "    return (\n",
    "        (\n",
    "            C[\"pose\", \"p\"].set(base_grid[0][fwd_index] + sample.get_retval().p)\n",
    "            | C[\"pose\", \"hd\"].set(base_grid[1][fwd_index] + sample.get_retval().hd)\n",
    "        ),\n",
    "        C[\"bwd_index\"].set(len(log_weights) - 1 - fwd_index)\n",
    "    )\n",
    "\n",
    "# Backwards proposal simply guesses according to the prior over steps, nothing fancier.\n",
    "@genjax.gen\n",
    "def grid_bwd_proposal(new_sample, args):\n",
    "    base_grid, _, full_model_args = args\n",
    "    step_model_args = (full_model_args[0], full_model_args[2], full_model_args[3])\n",
    "\n",
    "    log_weights = jax.vmap(\n",
    "        lambda p, hd:\n",
    "            step_model.assess(\n",
    "                C[\"p\"].set(p + new_sample.get_retval().p)\n",
    "                | C[\"hd\"].set(hd + new_sample.get_retval().hd),\n",
    "                step_model_args\n",
    "            )[0]\n",
    "    )(*base_grid)\n",
    "\n",
    "    _ = genjax.categorical(log_weights) @ \"bwd_index\"\n",
    "    # Since the backward proposal is only used for assessing the above choice,\n",
    "    # no further computation is necessary.\n",
    "\n",
    "def localization_sis_plus_grid_rejuv(motion_settings, sensor_noise, M_grid, N_grid, observations):\n",
    "    base_grid = make_poses_grid_array(\n",
    "        jnp.array([-M_grid / 2, M_grid / 2]).T,\n",
    "        N_grid\n",
    "    )\n",
    "    return SISwithRejuvenation(\n",
    "        robot_inputs[\"start\"],\n",
    "        robot_inputs[\"controls\"],\n",
    "        observations,\n",
    "        importance=lambda key, pose, control, observation: full_model_kernel.importance(\n",
    "            key,\n",
    "            C[\"sensor\", \"distance\"].set(observation),\n",
    "            (motion_settings, sensor_noise, pose, control),\n",
    "        ),\n",
    "        rejuvenate=lambda key, sample, pose, control, observation: run_SMCP3_step(\n",
    "            grid_fwd_proposal,\n",
    "            grid_bwd_proposal,\n",
    "            key,\n",
    "            sample,\n",
    "            (base_grid, observation, (motion_settings, sensor_noise, pose, control))\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Here are the graphics gadgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # World plot\n",
    "\n",
    "# (\n",
    "#     world_plot\n",
    "#     + {\"title\": \"Given data\"}\n",
    "# )\n",
    "\n",
    "\n",
    "# # Pose plot\n",
    "\n",
    "# some_pose = Pose(jnp.array([6.0, 15.0]), jnp.array(0.0))\n",
    "# Plot.html(\"Click-drag on pose to change location.  Shift-click-drag on pose to change heading.\") | (\n",
    "#     world_plot\n",
    "#     + pose_widget(\"pose\", some_pose, color=\"blue\")\n",
    "# ) | Plot.html(js(\"`pose = Pose([${$state.pose.p.map((x) => x.toFixed(2))}], ${$state.pose.hd.toFixed(2)})`\"))\n",
    "\n",
    "# some_poses = jax.vmap(random_pose)(jax.random.split(key, 20))\n",
    "# (\n",
    "#     world_plot\n",
    "#     + pose_plots(some_poses, color=\"green\")\n",
    "#     + {\"title\": \"Some poses\"}\n",
    "# )\n",
    "\n",
    "\n",
    "# # Ideal sensor plot\n",
    "\n",
    "# some_pose = Pose(jnp.array([6.0, 15.0]), jnp.array(0.0))\n",
    "# (\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + plot_sensors(js(\"$state.pose\"), js(\"$state.pose_readings\"), sensor_angles, show_legend=True)\n",
    "#         + pose_widget(\"pose\", some_pose, color=\"blue\")\n",
    "#     )\n",
    "#     | Plot.html(js(\"`pose = Pose([${$state.pose.p.map((x) => x.toFixed(2))}], ${$state.pose.hd.toFixed(2)})`\"))\n",
    "#     | Plot.initialState({\n",
    "#         \"pose_readings\": ideal_sensor(some_pose)\n",
    "#     })\n",
    "#     | Plot.onChange({\n",
    "#         \"pose\": lambda widget, _: update_ideal_sensors(widget, \"pose\")\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# some_poses = jax.vmap(random_pose)(jax.random.split(sub_key, 20))\n",
    "# some_readings = jax.vmap(ideal_sensor)(some_poses)\n",
    "# Plot.Frames([\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + plot_sensors(pose, some_readings[i], sensor_angles, show_legend=True)\n",
    "#         + pose_plots(pose)\n",
    "#     )\n",
    "#     for i, pose in enumerate(some_poses)\n",
    "# ], fps=2)\n",
    "\n",
    "\n",
    "# # Noisy sensor plot\n",
    "\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# some_pose = Pose(jnp.array([6.0, 15.0]), jnp.array(0.0))\n",
    "# def on_slider_change(widget, _):\n",
    "#     update_noisy_sensors(widget, \"pose\", \"noise_slider\")\n",
    "# (\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + plot_sensors(js(\"$state.pose\"), js(\"$state.pose_readings\"), sensor_angles)\n",
    "#         + pose_widget(\"pose\", some_pose, color=\"blue\")\n",
    "#     )\n",
    "#     | noise_slider(\"noise_slider\", \"Sensor noise =\", model_sensor_noise)\n",
    "#     | Plot.html(js(\"`pose = Pose([${$state.pose.p.map((x) => x.toFixed(2))}], ${$state.pose.hd.toFixed(2)})`\"))\n",
    "#     | Plot.initialState({\n",
    "#         \"k\": jax.random.key_data(k1),\n",
    "#         \"pose_readings\": noisy_sensor(k2, some_pose, model_sensor_noise)\n",
    "#     }, sync={\"k\"})\n",
    "#     | Plot.onChange({\"pose\": on_slider_change, \"noise_slider\": on_slider_change})\n",
    "# )\n",
    "\n",
    "\n",
    "# # Guess-the-pose demo\n",
    "\n",
    "# key, k1, k2, k3 = jax.random.split(key, 4)\n",
    "# guess_pose = Pose(jnp.array([2.0, 16.0]), jnp.array(0.0))\n",
    "# target_pose = Pose(jnp.array([15.0, 4.0]), jnp.array(-1.6))\n",
    "# def likelihood_function(cm, pose, sensor_noise):\n",
    "#     return sensor_model.assess(cm, (pose, sensor_angles, sensor_noise))[0]\n",
    "# def on_guess_pose_chage(widget, _):\n",
    "#     update_ideal_sensors(widget, \"guess\")\n",
    "#     widget.state.update({\"likelihood\":\n",
    "#         likelihood_function(\n",
    "#             C[\"distance\"].set(widget.state.target_readings),\n",
    "#             pose_at(widget.state, \"guess\"),\n",
    "#             model_sensor_noise\n",
    "#         )\n",
    "#     })\n",
    "# def on_target_pose_chage(widget, _):\n",
    "#     update_noisy_sensors(widget, \"target\", \"noise_slider\")\n",
    "#     widget.state.update({\"likelihood\":\n",
    "#         likelihood_function(\n",
    "#             C[\"distance\"].set(widget.state.target_readings),\n",
    "#             pose_at(widget.state, \"guess\"),\n",
    "#             model_sensor_noise\n",
    "#         )\n",
    "#     })\n",
    "# (\n",
    "#     Plot.Grid(\n",
    "#         (\n",
    "#             world_plot\n",
    "#             + plot_sensors(js(\"$state.guess\"), js(\"$state.target_readings\"), sensor_angles)\n",
    "#             + pose_widget(\"guess\", guess_pose, color=\"blue\")\n",
    "#             + Plot.cond(js(\"$state.show_target_pose\"),\n",
    "#                 pose_widget(\"target\", target_pose, color=\"gold\"))\n",
    "#         ),\n",
    "#         (\n",
    "#             Plot.rectY(\n",
    "#                 Plot.js(\"\"\"\n",
    "#                 const data = [];\n",
    "#                 for (let i = 0; i < $state.guess_readings.length; i++) {\n",
    "#                     data.push({\n",
    "#                         \"sensor index\": i - 0.15,\n",
    "#                         \"distance\": $state.guess_readings[i],\n",
    "#                         \"group\": \"wall distances from guess pose\"\n",
    "#                     });\n",
    "#                     data.push({\n",
    "#                         \"sensor index\": i + 0.15,\n",
    "#                         \"distance\": $state.target_readings[i],\n",
    "#                         \"group\": \"sensor readings from hidden pose\"\n",
    "#                     });\n",
    "#                 }\n",
    "#                 return data;\n",
    "#                 \"\"\", expression=False),\n",
    "#                 x=\"sensor index\",\n",
    "#                 y=\"distance\",\n",
    "#                 fill=\"group\",\n",
    "#                 interval=0.5\n",
    "#             )\n",
    "#             + Plot.domainY([0, 15])\n",
    "#             + {\"height\": 300, \"marginBottom\": 50}\n",
    "#             + Plot.color_map({\n",
    "#                 \"wall distances from guess pose\": \"blue\",\n",
    "#                 \"sensor readings from hidden pose\": \"gold\"\n",
    "#             })\n",
    "#             + Plot.colorLegend()\n",
    "#             + {\"legend\": {\"anchor\": \"middle\", \"x\": 0.5, \"y\": 1.2}}\n",
    "#             | [\n",
    "#                 \"div\",\n",
    "#                 {\"class\": \"text-lg mt-2 text-center w-full\"},\n",
    "#                 Plot.js(\"'log likelihood (greater is better): ' + $state.likelihood.toFixed(2)\")\n",
    "#             ]\n",
    "#         ),\n",
    "#         cols=2\n",
    "#     )\n",
    "#     | noise_slider(\"noise_slider\", \"Sensor noise =\", model_sensor_noise)\n",
    "#     | (\n",
    "#         Plot.html([\n",
    "#             \"label\",\n",
    "#             {\"class\": \"flex items-center gap-2 cursor-pointer\"},\n",
    "#             [\n",
    "#                 \"input\",\n",
    "#                 {\n",
    "#                     \"type\": \"checkbox\",\n",
    "#                     \"checked\": js(\"$state.show_target_pose\"),\n",
    "#                     \"onChange\": js(\"(e) => $state.show_target_pose = e.target.checked\")\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"show target pose\"\n",
    "#         ])\n",
    "#         & Plot.html(js(\"`guess = Pose([${$state.guess.p.map((x) => x.toFixed(2))}], ${$state.guess.hd.toFixed(2)})`\"))\n",
    "#         & Plot.html(js(\"`target = Pose([${$state.target.p.map((x) => x.toFixed(2))}], ${$state.target.hd.toFixed(2)})`\"))\n",
    "#     )\n",
    "#     | Plot.initialState(\n",
    "#         {\n",
    "#             \"k\": jax.random.key_data(k1),\n",
    "#             \"guess_readings\": ideal_sensor(guess_pose),\n",
    "#             \"target_readings\": (initial_target_readings := noisy_sensor(k3, target_pose, model_sensor_noise)),\n",
    "#             \"likelihood\": likelihood_function(C[\"distance\"].set(initial_target_readings), guess_pose, model_sensor_noise),\n",
    "#             \"show_target_pose\": False,\n",
    "#         }, sync={\"k\", \"target_readings\"})\n",
    "#     | Plot.onChange({\n",
    "#             \"guess\": on_guess_pose_chage,\n",
    "#             \"target\": on_target_pose_chage,\n",
    "#             \"noise_slider\": on_target_pose_chage,\n",
    "#     })\n",
    "# )\n",
    "\n",
    "\n",
    "# # Pose prior plots\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# some_poses = jax.vmap(lambda k: whole_map_prior.simulate(k, ()))(jax.random.split(sub_key, 100)).get_retval()\n",
    "# (\n",
    "#     world_plot\n",
    "#     + pose_plots(some_poses, color=\"green\")\n",
    "#     + {\"title\": \"Some poses\"}\n",
    "# )\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# some_poses = jax.vmap(lambda k: two_room_prior.simulate(k, ()))(jax.random.split(sub_key, 100)).get_retval()\n",
    "# (\n",
    "#     world_plot\n",
    "#     + pose_plots(some_poses, color=\"green\")\n",
    "#     + {\"title\": \"Some poses\"}\n",
    "# )\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# some_poses = jax.vmap(lambda k: localized_prior.simulate(k, ()))(jax.random.split(sub_key, 100)).get_retval()\n",
    "# (\n",
    "#     world_plot\n",
    "#     + pose_plots(some_poses, color=\"green\")\n",
    "#     + {\"title\": \"Some poses\"}\n",
    "# )\n",
    "\n",
    "\n",
    "# # Grid search widget\n",
    "\n",
    "# N_grid = jnp.array([50, 50, 20])\n",
    "# N_keep = 1000  # keep the top this many out of the total `jnp.prod(N_grid)` of them\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# camera_pose = Pose(jnp.array([2.0, 16.0]), jnp.array(0.0))\n",
    "# def grid_search_handler(widget, k, readings):\n",
    "#     model_noise = float(getattr(widget.state, \"model_noise\"))\n",
    "#     jitted_posterior = make_posterior_density_fn(widget.state.prior, readings, model_noise)\n",
    "#     grid_poses = make_poses_grid(world[\"bounding_box\"], N_grid)\n",
    "#     posterior_densities = jax.vmap(jitted_posterior)(grid_poses)\n",
    "#     best = jnp.argsort(posterior_densities, descending=True)[0:N_keep]\n",
    "#     widget.state.update({\n",
    "#         \"grid_poses\": grid_poses[best].as_dict(),\n",
    "#         \"best\": grid_poses[best[0]].as_dict()\n",
    "#     })\n",
    "# camera_widget(\n",
    "#     sub_key,\n",
    "#     camera_pose,\n",
    "#     \"grid search\",\n",
    "#     grid_search_handler,\n",
    "#     result_plots=(\n",
    "#         pose_plots(js(\"$state.grid_poses\"), color=\"green\", opacity=jnp.arange(1.0, 0.0, -1/N_keep))\n",
    "#         + pose_plots(js(\"$state.best\"), color=\"purple\")\n",
    "#     ),\n",
    "#     bottom_elements=(\n",
    "#         Plot.html(\n",
    "#             # For some reason `toFixed` very stubbonrly malfunctions in the following line:\n",
    "#             Plot.js(\"\"\"$state.target_exists ?\n",
    "#                                 `best = Pose([${$state.best.p.map((x) => x.toFixed(2))}], ${$state.best.hd.toFixed(2)})` : ''\"\"\")\n",
    "#         )\n",
    "#     ),\n",
    "#     initial_state={\n",
    "#         \"grid_poses\": {\"p\": [], \"hd\": []},\n",
    "#         \"best\": {\"p\": None, \"hd\": None},\n",
    "#     },\n",
    "# )\n",
    "\n",
    "\n",
    "# # Grid approximation sampler\n",
    "\n",
    "# N_grid = jnp.array([50, 50, 20])\n",
    "# N_samples = 100\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# camera_pose = Pose(jnp.array([15.13, 14.16]), jnp.array(1.5))\n",
    "# def grid_approximation_handler(widget, k, readings):\n",
    "#     model_noise = float(getattr(widget.state, \"model_noise\"))\n",
    "#     jitted_posterior = make_posterior_density_fn(widget.state.prior, readings, model_noise)\n",
    "#     grid_poses = make_poses_grid(world[\"bounding_box\"], N_grid)\n",
    "#     posterior_densities = jax.vmap(jitted_posterior)(grid_poses)\n",
    "#     def grid_sample_one(k):\n",
    "#         return grid_poses[genjax.categorical.propose(k, (posterior_densities,))[2]]\n",
    "#     grid_samples = jax.vmap(grid_sample_one)(jax.random.split(k, N_samples))\n",
    "#     widget.state.update({\n",
    "#         \"sample_poses\": grid_samples,\n",
    "#     })\n",
    "# camera_widget(\n",
    "#     sub_key,\n",
    "#     camera_pose,\n",
    "#     \"grid sampler\",\n",
    "#     grid_approximation_handler,\n",
    "#     result_plots=pose_plots(js(\"$state.sample_poses\"), color=\"green\"),\n",
    "#     initial_state={\"sample_poses\": {\"p\": [], \"hd\": []}},\n",
    "# )\n",
    "\n",
    "\n",
    "# # Importance resampling widget\n",
    "\n",
    "# N_presamples = 1000\n",
    "# N_samples = 100\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# camera_pose = Pose(jnp.array([15.13, 14.16]), jnp.array(1.5))\n",
    "# def importance_resampling_handler(widget, k, readings):\n",
    "#     model_noise = float(getattr(widget.state, \"model_noise\"))\n",
    "#     jitted_posterior = make_posterior_density_fn(widget.state.prior, readings, model_noise)\n",
    "#     def importance_resample_one(k):\n",
    "#         k1, k2 = jax.random.split(k)\n",
    "#         presamples = jax.vmap(random_pose)(jax.random.split(k1, N_presamples))\n",
    "#         posterior_densities = jax.vmap(jitted_posterior)(presamples)\n",
    "#         return presamples[genjax.categorical.propose(k2, (posterior_densities,))[2]]\n",
    "#     grid_samples = jax.vmap(importance_resample_one)(jax.random.split(k, N_samples))\n",
    "#     widget.state.update({\n",
    "#         \"sample_poses\": grid_samples,\n",
    "#     })\n",
    "# camera_widget(\n",
    "#     sub_key,\n",
    "#     camera_pose,\n",
    "#     \"importance resampler\",\n",
    "#     importance_resampling_handler,\n",
    "#     result_plots=pose_plots(js(\"$state.sample_poses\"), color=\"green\"),\n",
    "#     initial_state={\"sample_poses\": {\"p\": [], \"hd\": []}},\n",
    "# )\n",
    "\n",
    "\n",
    "# # Markov chain Monte Carlo widget\n",
    "\n",
    "# N_MH_steps = 1000\n",
    "# N_samples = 100\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# camera_pose = Pose(jnp.array([15.13, 14.16]), jnp.array(1.5))\n",
    "# def MCMC_handler(widget, k, readings):\n",
    "#     model_noise = float(getattr(widget.state, \"model_noise\"))\n",
    "#     jitted_posterior = make_posterior_density_fn(widget.state.prior, readings, model_noise)\n",
    "#     def do_MH_step(pose_posterior_density, k):\n",
    "#         pose, posterior_density = pose_posterior_density\n",
    "#         k1, k2 = jax.random.split(k)\n",
    "#         p_hd = pose.as_array()\n",
    "#         delta = jnp.array([0.5, 0.5, 0.1])\n",
    "#         mins = jnp.maximum(p_hd - delta, world[\"bounding_box\"][:, 0])\n",
    "#         maxs = jnp.minimum(p_hd + delta, world[\"bounding_box\"][:, 1])\n",
    "#         new_p_hd = jax.random.uniform(k1, shape=(3,), minval=mins, maxval=maxs)\n",
    "#         new_pose = Pose(new_p_hd[0:2], new_p_hd[2])\n",
    "#         new_posterior = jitted_posterior(new_pose)\n",
    "#         accept = (jnp.log(genjax.uniform.propose(k2, ())[2]) <= new_posterior - posterior_density)\n",
    "#         return (\n",
    "#             jax.tree.map(\n",
    "#                 lambda x, y: jnp.where(accept, x, y),\n",
    "#                 (new_pose, posterior_density),\n",
    "#                 (pose, posterior_density)\n",
    "#             ),\n",
    "#             None\n",
    "#         )\n",
    "#     def sample_MH_one(k):\n",
    "#         k1, k2 = jax.random.split(k)\n",
    "#         start_pose = random_pose(k1)\n",
    "#         start_posterior = jitted_posterior(start_pose)\n",
    "#         return jax.lax.scan(do_MH_step, (start_pose, start_posterior), jax.random.split(k2, N_MH_steps))[0][0]\n",
    "#     grid_samples = jax.vmap(sample_MH_one)(jax.random.split(k, N_samples))\n",
    "#     widget.state.update({\n",
    "#         \"sample_poses\": grid_samples,\n",
    "#     })\n",
    "# camera_widget(\n",
    "#     sub_key,\n",
    "#     camera_pose,\n",
    "#     \"MCMC trajectories\",\n",
    "#     MCMC_handler,\n",
    "#     result_plots=pose_plots(js(\"$state.sample_poses\"), color=\"green\"),\n",
    "#     initial_state={\"sample_poses\": {\"p\": [], \"hd\": []}},\n",
    "# )\n",
    "\n",
    "\n",
    "# # Robot motion\n",
    "\n",
    "# def update_unphysical_path(widget, _):\n",
    "#     start = pose_at(widget.state, \"start\")\n",
    "#     widget.state.update({\n",
    "#         \"path\": integrate_controls_unphysical(robot_inputs | {\"start\": start})\n",
    "#     })\n",
    "# (\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + pose_plots(js(\"$state.path\"), color=Plot.constantly(\"path from integrating controls (UNphysical)\"))\n",
    "#         + pose_widget(\"start\", robot_inputs[\"start\"], color=Plot.constantly(\"start pose\"))\n",
    "#         + Plot.color_map({\"start pose\": \"blue\", \"path from integrating controls (UNphysical)\": \"green\"})\n",
    "#     )\n",
    "#     | Plot.html(js(\"`start = Pose([${$state.start.p.map((x) => x.toFixed(2))}], ${$state.start.hd.toFixed(2)})`\"))\n",
    "#     | Plot.initialState({\n",
    "#         \"path\": integrate_controls_unphysical(robot_inputs)\n",
    "#     })\n",
    "#     | Plot.onChange({\"start\": update_unphysical_path})\n",
    "# )\n",
    "\n",
    "# def update_physical_path(widget, _):\n",
    "#     start = pose_at(widget.state, \"start\")\n",
    "#     widget.state.update({\n",
    "#         \"path\": integrate_controls_physical(robot_inputs | {\"start\": start})\n",
    "#     })\n",
    "# (\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + pose_plots(js(\"$state.path\"), color=Plot.constantly(\"path from integrating controls (physical)\"))\n",
    "#         + pose_widget(\"start\", robot_inputs[\"start\"], color=Plot.constantly(\"start pose\"))\n",
    "#         + Plot.color_map({\"start pose\": \"blue\", \"path from integrating controls (physical)\": \"green\"})\n",
    "#     )\n",
    "#     | Plot.html(js(\"`start = Pose([${$state.start.p.map((x) => x.toFixed(2))}], ${$state.start.hd.toFixed(2)})`\"))\n",
    "#     | Plot.initialState({\n",
    "#         \"path\": integrate_controls_physical(robot_inputs)\n",
    "#     })\n",
    "#     | Plot.onChange({\"start\": update_physical_path})\n",
    "# )\n",
    "\n",
    "\n",
    "# # Step model\n",
    "\n",
    "# N_samples = 50\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# def update_confidence_circle(widget, _):\n",
    "#     step = pose_at(widget.state, \"step\")\n",
    "#     step_vector = step.p - robot_inputs[\"start\"].p\n",
    "#     tilted_start_hd = jnp.atan2(step_vector[1], step_vector[0])\n",
    "#     tilted_start = Pose(robot_inputs[\"start\"].p, tilted_start_hd)\n",
    "#     ds = jnp.linalg.norm(step_vector)\n",
    "#     dhd = (step.hd - tilted_start_hd + jnp.pi) % (2 * jnp.pi) - jnp.pi\n",
    "#     widget.state.update({\n",
    "#         \"start\": tilted_start.as_dict(),\n",
    "#         \"control\": {\"ds\": ds, \"dhd\": dhd}\n",
    "#     })\n",
    "#     k1, k2 = jax.random.split(jax.random.wrap_key_data(widget.state.k))\n",
    "#     samples = jax.vmap(step_model.propose, in_axes=(0, None))(\n",
    "#         jax.random.split(k1, N_samples),\n",
    "#         (model_motion_settings, tilted_start, Control(ds, dhd)),\n",
    "#     )[2]\n",
    "#     widget.state.update({\n",
    "#         \"k\": jax.random.key_data(k2),\n",
    "#         \"samples\": samples.as_dict()\n",
    "#     })\n",
    "# (\n",
    "#     (\n",
    "#         world_plot\n",
    "#         + confidence_circle(js(\"[$state.step.p]\"), model_motion_settings[\"p_noise\"])\n",
    "#         + pose_plots(js(\"$state.samples\"), color=Plot.constantly(\"samples from the step model\"))\n",
    "#         + pose_plots(js(\"$state.start\"), color=Plot.constantly(\"start pose\"))\n",
    "#         + pose_widget(\"step\", robot_inputs[\"start\"], color=Plot.constantly(\"attempt to step to here\"))\n",
    "#         + Plot.color_map({\n",
    "#             \"start pose\": \"black\",\n",
    "#             \"attempt to step to here\": \"blue\",\n",
    "#             \"samples from the step model\": \"green\",\n",
    "#         })\n",
    "#     )\n",
    "#     | Plot.html(js(\"`control = Control(${$state.control.ds.toFixed(2)}, ${$state.control.dhd.toFixed(2)})`\"))\n",
    "#     | Plot.initialState({\n",
    "#         \"start\": robot_inputs[\"start\"].as_dict(),\n",
    "#         \"control\": {\"ds\": 0.0, \"dhd\": 0.0},\n",
    "#         \"k\": jax.random.key_data(k1),\n",
    "#         \"samples\": (\n",
    "#             jax.vmap(step_model.propose, in_axes=(0, None))(\n",
    "#                 jax.random.split(k2, N_samples),\n",
    "#                 (model_motion_settings, robot_inputs[\"start\"], robot_inputs[\"controls\"][0]),\n",
    "#             )[2].as_dict()\n",
    "#         ),\n",
    "#     }, sync={\"k\"})\n",
    "#     | Plot.onChange({\"step\": update_confidence_circle})\n",
    "# )\n",
    "\n",
    "\n",
    "# # Path model\n",
    "\n",
    "# key, sample_key = jax.random.split(key)\n",
    "# path = path_model.propose(sample_key, (model_motion_settings,))[2][1]\n",
    "# Plot.Frames(\n",
    "#     [\n",
    "#         plot_path_with_confidence(path, step)\n",
    "#         + Plot.title(\"Motion model (samples)\")\n",
    "#         for step in range(len(path))\n",
    "#     ],\n",
    "#     fps=2,\n",
    "# )\n",
    "\n",
    "# N_samples = 12\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# sample_paths = jax.vmap(\n",
    "#     lambda k:\n",
    "#         path_model.propose(k, (model_motion_settings,))[2][1]\n",
    "# )(jax.random.split(sub_key, N_samples))\n",
    "# Plot.html([\n",
    "#     \"div.grid.grid-cols-2.gap-4\",\n",
    "#     *[walls_plot + pose_plots(path) + {\"maxWidth\": 300, \"aspectRatio\": 1} for path in sample_paths]\n",
    "# ])\n",
    "\n",
    "\n",
    "# # Full model\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# cm, _, retval = full_model.propose(sub_key, (model_motion_settings, model_sensor_noise))\n",
    "# animate_path_and_sensors(retval[1], cm[\"steps\", \"sensor\", \"distance\"])\n",
    "\n",
    "\n",
    "# # Updating traces\n",
    "\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# trace = step_model.simulate(\n",
    "#     k1,\n",
    "#     (model_motion_settings, robot_inputs[\"start\"], robot_inputs[\"controls\"][0]),\n",
    "# )\n",
    "# rotated_trace, rotated_trace_weight_diff, _, _ = trace.update(\n",
    "#     k2, C[\"hd\"].set(jnp.pi / 2)\n",
    "# )\n",
    "# (\n",
    "#     world_plot\n",
    "#     + pose_plots(trace.get_retval(), color=Plot.constantly(\"some pose\"))\n",
    "#     + pose_plots(\n",
    "#         rotated_trace.get_retval(), color=Plot.constantly(\"with heading modified\")\n",
    "#     )\n",
    "#     + Plot.color_map({\"some pose\": \"green\", \"with heading modified\": \"red\"})\n",
    "#     + Plot.title(\"Modifying a heading\")\n",
    "# ) | html(f\"score ratio: {rotated_trace_weight_diff}\")\n",
    "\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# trace = path_model.simulate(k1, (model_motion_settings,))\n",
    "# rotated_first_step, rotated_first_step_weight_diff, _, _ = trace.update(\n",
    "#     k2, C[\"steps\", 0, \"hd\"].set(jnp.pi / 2)\n",
    "# )\n",
    "# (\n",
    "#     world_plot\n",
    "#     + [\n",
    "#         pose_plots(pose, color=Plot.constantly(\"with heading modified\"))\n",
    "#         for pose in rotated_first_step.get_retval()[1]\n",
    "#     ]\n",
    "#     + [\n",
    "#         pose_plots(pose, color=Plot.constantly(\"some path\"))\n",
    "#         for pose in trace.get_retval()[1]\n",
    "#     ]\n",
    "#     + Plot.color_map({\"some path\": \"green\", \"with heading modified\": \"red\"})\n",
    "# ) | html(f\"score ratio: {rotated_first_step_weight_diff}\")\n",
    "\n",
    "\n",
    "# # Animating full traces\n",
    "\n",
    "# key, sub_key = jax.random.split(key)\n",
    "# tr = full_model.simulate(sub_key, (model_motion_settings, model_sensor_noise))\n",
    "# animate_full_trace(tr)\n",
    "\n",
    "# (\n",
    "#     (\n",
    "#         html(\"low motion-deviation data\")\n",
    "#         | animate_full_trace(trace_low_deviation, frame_key=\"frame\")\n",
    "#     ) & (\n",
    "#         html(\"high motion-deviation data\")\n",
    "#         | animate_full_trace(trace_high_deviation, frame_key=\"frame\")\n",
    "#     )\n",
    "# ) | Plot.Slider(\"frame\", 0, T, fps=2)\n",
    "\n",
    "\n",
    "# # Making traces with constraints\n",
    "\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# trace_low, log_weight_low = full_model.importance(\n",
    "#     k1, constraints_low_deviation, (model_motion_settings, model_sensor_noise)\n",
    "# )\n",
    "# trace_high, log_weight_high = full_model.importance(\n",
    "#     k2, constraints_high_deviation, (model_motion_settings, model_sensor_noise)\n",
    "# )\n",
    "# (\n",
    "#     (\n",
    "#         html(\"fresh path sample\", \"fixed low motion-deviation sensor data\")\n",
    "#         | animate_full_trace(trace_low, frame_key=\"frame\")\n",
    "#         | html(f\"log_weight: {log_weight_low}\")\n",
    "#     ) & (\n",
    "#         html(\"fresh path sample\", \"fixed high motion-deviation sensor data\")\n",
    "#         | animate_full_trace(trace_high, frame_key=\"frame\")\n",
    "#         | html(f\"log_weight: {log_weight_high}\")\n",
    "#     )\n",
    "# ) | Plot.Slider(\"frame\", 0, T, fps=2)\n",
    "\n",
    "\n",
    "# Unlikely likelihoods histograms\n",
    "\n",
    "# N_samples = 200\n",
    "# key, k1, k2, k3, k4 = jax.random.split(key, 5)\n",
    "# traces_generated_low_deviation, low_weights = jax.vmap(\n",
    "#     full_model.importance, in_axes=(0, None, None)\n",
    "# )(\n",
    "#     jax.random.split(k1, N_samples),\n",
    "#     constraints_low_deviation,\n",
    "#     (model_motion_settings, model_sensor_noise),\n",
    "# )\n",
    "# traces_generated_high_deviation, high_weights = jax.vmap(\n",
    "#     full_model.importance, in_axes=(0, None, None)\n",
    "# )(\n",
    "#     jax.random.split(k2, N_samples),\n",
    "#     constraints_high_deviation,\n",
    "#     (model_motion_settings, model_sensor_noise),\n",
    "# )\n",
    "# traces_simulated = jax.vmap(\n",
    "#     full_model.simulate, in_axes=(0, None)\n",
    "# )(\n",
    "#     jax.random.split(k3, N_samples),\n",
    "#     (model_motion_settings, model_sensor_noise),\n",
    "# )\n",
    "# simulated_weights = jax.vmap(\n",
    "#     lambda trace, k: trace.project(k, S[\"steps\", \"sensor\", \"distance\"])\n",
    "# )(traces_simulated, jax.random.split(k4, N_samples))\n",
    "# (\n",
    "#     html(\"likelihoods of low motion-deviation data\")\n",
    "#     | Plot.histogram(values=low_weights, thresholds=10)\n",
    "# ) & (\n",
    "#     html(\"likelihoods of high motion-deviation data\")\n",
    "#     | Plot.histogram(values=high_weights, thresholds=10)\n",
    "# ) & (\n",
    "#     html(\"likelihoods of random data\")\n",
    "#     | Plot.histogram(values=simulated_weights, thresholds=10)\n",
    "# )\n",
    "\n",
    "\n",
    "# # Whole-path importance resampling\n",
    "\n",
    "# N_presamples = 2000\n",
    "# N_samples = 20\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# low_posterior = importance_resample(\n",
    "#     k1, constraints_low_deviation, model_motion_settings, model_sensor_noise, N_presamples, N_samples\n",
    "# )\n",
    "# high_posterior = importance_resample(\n",
    "#     k2, constraints_high_deviation, model_motion_settings, model_sensor_noise, N_presamples, N_samples\n",
    "# )\n",
    "# plot_inference_result(\n",
    "#     (\"importance resampling on low motion-deviation data\",),\n",
    "#     \"importance resamples\",\n",
    "#     jax.vmap(get_path)(low_posterior),\n",
    "#     path_low_deviation\n",
    "# ) & plot_inference_result(\n",
    "#     (\"importance resampling on high motion-deviation data\",),\n",
    "#     \"importance resamples\",\n",
    "#     jax.vmap(get_path)(high_posterior),\n",
    "#     path_high_deviation\n",
    "# )\n",
    "\n",
    "\n",
    "# # Sequential importance resampling\n",
    "\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# N_particles = 20\n",
    "# sis_result_low = localization_sis(\n",
    "#     model_motion_settings, model_sensor_noise, observations_low_deviation\n",
    "# ).run(k1, N_particles)\n",
    "# sis_result_high = localization_sis(\n",
    "#     model_motion_settings, model_sensor_noise, observations_high_deviation\n",
    "# ).run(k2, N_particles)\n",
    "# plot_inference_result(\n",
    "#     (\"SIS on low motion-deviation data\",),\n",
    "#     \"sequential importance resamples\",\n",
    "#     [pytree_transpose(path) for path in sis_result_low.backtrack()],\n",
    "#     path_low_deviation,\n",
    "#     history_paths=[pytree_transpose(path) for path in sis_result_low.flood_fill()]\n",
    "# ) & plot_inference_result(\n",
    "#     (\"SIS on high motion-deviation data\",),\n",
    "#     \"sequential importance resamples\",\n",
    "#     [pytree_transpose(path) for path in sis_result_high.backtrack()],\n",
    "#     path_high_deviation,\n",
    "#     history_paths=[pytree_transpose(path) for path in sis_result_high.flood_fill()]\n",
    "# )\n",
    "\n",
    "\n",
    "# # SMCP3\n",
    "\n",
    "# N_particles = 20\n",
    "# M_grid = jnp.array([0.5, 0.5, (3 / 10) * degrees])\n",
    "# N_grid = jnp.array([15, 15, 15])\n",
    "# key, k1, k2 = jax.random.split(key, 3)\n",
    "# sis_result = localization_sis(\n",
    "#     model_motion_settings, model_sensor_noise, observations_high_deviation\n",
    "# ).run(k1, N_particles)\n",
    "# smcp3_result = localization_sis_plus_grid_rejuv(\n",
    "#     model_motion_settings, model_sensor_noise, M_grid, N_grid, observations_high_deviation\n",
    "# ).run(k2, N_particles)\n",
    "# plot_inference_result(\n",
    "#     (\"SIS without rejuvenation\", \"high motion-deviation data\"),\n",
    "#     \"samples\",\n",
    "#     [pytree_transpose(path) for path in sis_result.backtrack()],\n",
    "#     path_high_deviation,\n",
    "#     history_paths=[pytree_transpose(path) for path in sis_result.flood_fill()]\n",
    "# ) & plot_inference_result(\n",
    "#     (\"SIS with SMCP3 grid rejuvenation\", \"high motion-deviation data\"),\n",
    "#     \"samples\",\n",
    "#     [pytree_transpose(path) for path in smcp3_result.backtrack()],\n",
    "#     path_high_deviation,\n",
    "#     history_paths=[pytree_transpose(path) for path in smcp3_result.flood_fill()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Exercise 0\n",
    "\n",
    "Step through the lab notebook.  Experiment with each inference algorithm (grid search, grid resampling, importance resampling, MCMC for poses; SIR, SIS, SMCP3 for paths) and silently comment to yourself qualitatively on each's performance characteristics.  For what model parameters and data do they work well, and when not, and at what cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "The following two cells work together:\n",
    "* the first declares reproducible state;\n",
    "* the second generates a trace, runs inference over its sensor data, and displays all the results.\n",
    "\n",
    "\n",
    "The parameters have the following meanings.\n",
    "1. The world motion deviation corresponds to *how wide our hypotheses will need to range* in order to infer the path.\n",
    "2. The world sensor noise corresponds to *how reliable the data are* for doing this inference.\n",
    "3. The model motion deviation corresponds to *how wide our prior* over paths is.\n",
    "4. The model sensor noise corresponds to *how tolerant versus avoidant* we are of incongruous data.\n",
    "\n",
    "By varying the state in the first cell, investigate the following issues.  **To report your findings, copy-paste suitable reproducible state into the cells below, and add sufficient text/comments for the reader to follow.**\n",
    "1. Low world motion deviation and high world sensor noise:\n",
    "   * There is not much reliable information to work with, so inference does little to bias samples from the prior towards the posterior.  However, the prior is already somewhat close to the posterior, so global SIR appears to do well enough.  Although SMCP3 nails the answer, it does so at much greater computational expense.\n",
    "2. High world motion deviation and low world sensor noise:\n",
    "   * The reliable information clearly tells us our inference to do *something*.  However, the prior being far from the posterior, SIR has trouble producing good hypotheses, while SMCP3 is able to search for them.\n",
    "3. In the prior two scenarios, when might tighter/looser deviation/noise help/hurt inference?\n",
    "4. What inference computational cost (`N_this`, `N_that`) seems to be enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reproducible state here!\n",
    "\n",
    "key = jax.random.key(1)\n",
    "\n",
    "\n",
    "# Data generation params\n",
    "\n",
    "world_motion_settings = {\n",
    "    \"p_noise\": 0.15,\n",
    "    \"hd_noise\": 0.5 * degrees,\n",
    "}\n",
    "world_sensor_noise = 0.3\n",
    "\n",
    "\n",
    "# Inference params\n",
    "\n",
    "model_motion_settings = {\n",
    "    \"p_noise\": 0.15,\n",
    "    \"hd_noise\": 1 * degrees\n",
    "}\n",
    "model_sensor_noise = 0.1\n",
    "\n",
    "# SIR\n",
    "N_presamples = 2000\n",
    "N_samples = 20\n",
    "\n",
    "# SMCP3\n",
    "N_particles = 20\n",
    "M_grid = jnp.array([1.0, 1.0, (3 / 10) * degrees])\n",
    "N_grid = jnp.array([15, 15, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, k1, k2, k3 = jax.random.split(key, 4)\n",
    "\n",
    "some_trace = full_model.simulate(k1, (world_motion_settings, world_sensor_noise))\n",
    "some_path = get_path(some_trace)\n",
    "some_observations = get_sensors(some_trace)\n",
    "some_constraints = C[\"steps\", \"sensor\", \"distance\"].set(some_observations)\n",
    "\n",
    "SIR_posterior = importance_resample(\n",
    "    k2, some_constraints, model_motion_settings, model_sensor_noise, N_presamples, N_samples\n",
    ")\n",
    "\n",
    "smcp3_result = localization_sis_plus_grid_rejuv(\n",
    "    model_motion_settings, model_sensor_noise, M_grid, N_grid, some_observations\n",
    ").run(k3, N_particles)\n",
    "\n",
    "(\n",
    "    animate_full_trace(some_trace)\n",
    "    | (\n",
    "        plot_inference_result(\n",
    "            (\"global importance resampling\",),\n",
    "            \"samples\",\n",
    "            jax.vmap(get_path)(SIR_posterior),\n",
    "            some_path\n",
    "        ) & plot_inference_result(\n",
    "            (\"SIS with SMCP3 grid rejuvenation\",),\n",
    "            \"samples\",\n",
    "            [pytree_transpose(path) for path in smcp3_result.backtrack()],\n",
    "            some_path,\n",
    "            history_paths=[pytree_transpose(path) for path in smcp3_result.flood_fill()]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Note the file `world_small.json` that describes a simpler \"small world\" place for the robot to operate.\n",
    "\n",
    "Write some (at least two) custom priors over poses *in the small world*.  Begin by sharing in words the intuitions that they are meant to capture, then implement them with generative functions.  Produce and visualize traces from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Execrcise 2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Make the following modifications.\n",
    "1. The make an additional model for generating \"world\" sensor data, in which `normal` noise has been replaced with `uniform` noise.\n",
    "2. Modify `joint_model` within `make_posterior_density_fn` to be *hierarchical*: the `model_noise` parameter (still passed to the original `sensor_model`) is changed from an explicit model parameter to a hyperparamter, drawn inside the model from the hyperprior `genjax.gamma(concentration=2.0, rate=20.0)`.\n",
    "3. At the same time as (2.), move the `model_noise` argument of `make_posterior_density_fn` to a parameter of the `lambda` expression passed to `jax.jit`, and incorporate its value in the choice map passed into `assess`.\n",
    "\n",
    "Modify some of the inference algorithms to range not over poses, but instead over pairs of pose and noise parameter.  (In the case of MH, remember to modify `do_MH_step` to wiggle the noise parameter too.)\n",
    "\n",
    "Play with the inference and **explain**, given a noise parameter for the data generation, what happens to the `sensor_noise` hyperparameter to get a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Exercise 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "How many steps (`N_MH_steps`) does MH need to jiggle a particle to get convergence towards the posterior distribution?  How can we *know* whether this is happening, in order to tune that constant?\n",
    "\n",
    "A simple way to test any posterior inference algorithm relies on the following fact: a posterior distribution is parametric in observed data values (upon which the conditioning took place); integrating the posterior distributions with respect to the prior predictive distribution recovers the prior distribution.  Said in more words, if we sample a latent parameter from the prior, sample observation datum with this latent parameter, and use posterior inference to sample a second latent parameter conditional on this observation datum, then the resulting composite (marginal) distribution over the second latent parameters should be indistinguishable from the prior.  Our code can perform this composition, so all we would need is a way to compare the composite to the prior, or really, any two distributions.\n",
    "\n",
    "In order to compare two distributions $p, q$ on a space $X$, we can instead compare their pushforwards under some test function $f : X \\to \\mathbf{R}$; that is, we can compare the distribution of values $f(x)$ where $x \\sim p$ to the distribution of values $f(y)$ where $y \\sim q$, reducing us to comparing two $\\mathbf{R}$-valued distributions.  A *rank-based test* for $\\mathbf{R}$-valued distributions draws independent samples $x_1, \\ldots, x_N \\sim p$ and $y \\sim q$, sorts the $x_i$, and computes the the index $I$ with $x_I \\leq y \\leq x_{I+1}$ (formally taking $x_0 = -\\infty$); if $p=q$ then we expect such indices $I$ to be uniformly distributed in $\\{0,1,\\ldots,N\\}$.  We generate $M$ such indices $I_1,\\ldots,I_M$ (keeping $N$ fixed, thus requiring $MN$ samples from $p$ and $M$ samples from $q$), plot their histogram, and see whether they look uniform.\n",
    "\n",
    "(Breaking ties in the ordering to determine $I$ is likely unnecessary in the continuous case, but is important in the discrete case: to get it right, choose $U_1, U_2, \\ldots, U_N, U$ continuous-uniformly on $[0,1]$, and when $y = x_i$ one declares $I < i$ if and only if $U < U_i$.)\n",
    "\n",
    "**Carry out this program** using the original `sample_MH_one` from the lab notebook as the posterior inference process, paired with each of the priors on the small and large map, and varying `N_MH_steps`.  Your test function could be the $x$-coordinate (or $y$-coordinate, or heading), or even the likelihood function.  How large does `N_MH_steps` need to be in order to achieve \"uniform\" histogram?  How does this size depend on the choice of map/prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Execrcise 4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Turn to the context of inference over *paths*, given a series of sensor data, as towards the end of the lab notebook.  **Code up** an alternate rejuvenation that performs MH to wiggle the most recent step of the path, leaving the weight unchanged.  (You might refer to the SMCP3 rejuvenation as an overall blueprint, plus the MH code for single-pose localization when working out the last-pose wiggling.)  How does it compare in efficacy and efficiency versus SMCP3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Exercise 5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "The SMCP3 rejuvenation's backward proposal simply guessed reverse grid indices from the prior over that robot step.  According to the theory, one should get more accurate results by instead guessing reverse grid indices from the posterior over that robot step, conditional on the information that the forward proposal sent the pose to the given one.  **Code up** this backwards proposal and comment on its efficacy versus efficiency.  Why might it not give much better results?  (Hint: the sensor noise model is Gaussian, which is self-conjugate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Exercise 6 here"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
